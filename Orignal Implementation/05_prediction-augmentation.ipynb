{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<br/>\n",
    "# Using `medGAN` to boost the prediction score with data augmentation on the MIMIC-III dataset of shape (1000, 100) with binary values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Sylvain Combettes](https://github.com/sylvaincom). <br/>\n",
    "Last update: Sep 11, 2019. Creation: Aug 12, 2019. <br/>\n",
    "My own `medGAN` repository: [medgan-tips](https://github.com/sylvaincom/medgan-tips) (based on Edward Choi's work). <br/>\n",
    "Edward Choi's original repository: [medgan](https://github.com/mp2893/medgan).\n",
    "\n",
    "Before reading this notebook, make sure that you have read my [medGAN repository](https://github.com/sylvaincom/medgan-tips)'s table of contents.\n",
    "\n",
    "### Using `medGAN` for data augmentation\n",
    "\n",
    "One application of `medGAN` is to use the fictitious generated dataset to help enrich the original real-life dataset (for data augmentation) to try to boost the prediction score. Here, we act as if we were in a real-life case and all that we have at our disposal is a real-life dataset (called `real`) of shape (1 000, 100). We want to use `medGAN` to generate a new fictitious realistic dataset called `fict` of 1 000 fictitious realistic samples (with 100 features as well). By adding (meaning concatenating) `fict` to `real`, we get a new augmented dataset (called `aug`) that has 2 000 samples (patients) (and also 100 features). We hope that building our model on `aug` helps our prediction algorithms make better predictions than building our model on `real`.\n",
    "Here is a recap:\n",
    "\n",
    "| | `real` dataset | `fict` dataset | `aug` dataset |\n",
    "|---|---|---|---|\n",
    "| number of samples | 1 000 | 1 000 | 2 000 |\n",
    "| number of features | 100 | 100 | 100 |\n",
    "\n",
    "_How do we compute the prediction score of a dataset?_ Out of the 100 features of our dataset, we select one that we call `target`. We are going to try to predict the `target` feature using the remaining 99 features. The scores are computed with cross-validation (thus we do not divide our dataset into train / valid / test). We choose our hyper-parameters with randomized search (using a random seed for reproducibility). Check [5) Can training on the augmented dataset help improve the prediction score with a real-life test set?](#aug2) for a different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Table of contents\n",
    "\n",
    "- [1) Loading the data](#load)\n",
    "- [2) Predicting the column `target` with (only) the original real-life dataset](#input)\n",
    "- [3) Predicting the column `target` with (only) the fictitious generated dataset](#output)\n",
    "- [4) Predicting the column `target` with data augmentation](#aug)\n",
    "- [5) Can training on the augmented dataset help improve the prediction score with a real-life test set?](#aug2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from time import process_time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn import datasets, model_selection, linear_model, neighbors, neural_network, naive_bayes\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"load\"></a>\n",
    "# 1) Loading the data\n",
    "\n",
    "## 1.1) Loading the real-life original dataset\n",
    "\n",
    "We refer to the real-life original dataset as `df_real`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the real-life original dataset is : (100, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>80</th>\n",
       "      <th>84</th>\n",
       "      <th>33</th>\n",
       "      <th>81</th>\n",
       "      <th>93</th>\n",
       "      <th>17</th>\n",
       "      <th>36</th>\n",
       "      <th>82</th>\n",
       "      <th>69</th>\n",
       "      <th>65</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>16</th>\n",
       "      <th>64</th>\n",
       "      <th>79</th>\n",
       "      <th>5</th>\n",
       "      <th>75</th>\n",
       "      <th>9</th>\n",
       "      <th>72</th>\n",
       "      <th>12</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    80   84   33   81   93   17   36   82   69   65  ...   1    16   64   79  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    5    75   9    72   12   37  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_array = pickle.load(open('training-data-small.matrix', 'rb')) # real-life dataset\n",
    "df_real = pd.DataFrame(real_data_array)\n",
    "#df_real = df_real.sample(1000, random_state=1)\n",
    "df_real = df_real.sample(100, axis=1, random_state=1)\n",
    "\n",
    "print('The shape of the real-life original dataset is :', df_real.shape)\n",
    "df_real.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Loading the fictitious generated dataset\n",
    "\n",
    "We refer to the fictitious generated dataset as `df_fict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the fictitious generated dataset is : (10000, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>80</th>\n",
       "      <th>84</th>\n",
       "      <th>33</th>\n",
       "      <th>81</th>\n",
       "      <th>93</th>\n",
       "      <th>17</th>\n",
       "      <th>36</th>\n",
       "      <th>82</th>\n",
       "      <th>69</th>\n",
       "      <th>65</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>16</th>\n",
       "      <th>64</th>\n",
       "      <th>79</th>\n",
       "      <th>5</th>\n",
       "      <th>75</th>\n",
       "      <th>9</th>\n",
       "      <th>72</th>\n",
       "      <th>12</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    80   84   33   81   93   17   36   82   69   65  ...   1    16   64   79  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    5    75   9    72   12   37  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fict = np.load('gen-samples.npy')\n",
    "df_fict = pd.DataFrame(fict, columns = df_real.columns).round(0)\n",
    "print('The shape of the fictitious generated dataset is :', df_fict.shape)\n",
    "df_fict.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Choosing the feature we are going to try to predict: `target`\n",
    "\n",
    "Which feature are we going to try to predict? We want to predict the feature with the highest variance. Indeed, a feature with a low variance, for example, with only 1s, is very easy to predict for new unseen samples because we put 1s. Thus, we want `target` to have a proportion of 1s that is the closest to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_real.sum()/df_real.shape[0], 'o')\n",
    "plt.xlabel('Index of feature')\n",
    "plt.ylabel('Proportion of 1s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature index of target is : 21\n",
      "Approx. proportion of 1s of target : 0.35\n"
     ]
    }
   ],
   "source": [
    "target = df_real.sum().idxmax(axis=0)\n",
    "print('The feature index of target is :', target)\n",
    "print('Approx. proportion of 1s of target :',\n",
    "      round(df_real[target].sum()/df_real.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"input\"></a>\n",
    "# 2) Predicting the column `target` with (only) the original real-life dataset\n",
    "\n",
    "## 2.1) Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 99) (100,)\n"
     ]
    }
   ],
   "source": [
    "df = df_real\n",
    "X_dataset = df.loc[:, df.columns != target].values\n",
    "y_dataset = np.ravel(df.loc[:, df.columns == target].values)\n",
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our benchmarking function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_and_time(model, X_dataset, y_dataset, cv):\n",
    "    \"\"\"\n",
    "    When there are no hyper-parameters.\n",
    "    This function returns a list with the scores and processing times of model.\n",
    "    The scores are calculated with cross_val_score (with K-Fold equal to cv).\n",
    "    \"\"\"\n",
    "    t_start = process_time()\n",
    "    scores = model_selection.cross_val_score(model, X_dataset, y_dataset, cv=cv)\n",
    "    t_stop = process_time()\n",
    "    part_l = [round(scores.mean(), 3), round(scores.std()*2, 3), str(datetime.timedelta(seconds=t_stop-t_start))]\n",
    "    return part_l\n",
    "\n",
    "#def score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv):\n",
    "    \"\"\"\n",
    "    When there are hyper-parameters.\n",
    "    This function returns a list with the scores and processing times of model.\n",
    "    The scores are calculated with RandomizedSearchCV (with K-Fold equal to cv) (we use a random seed).\n",
    "    \"\"\"\n",
    "    #t_start = process_time()\n",
    "    #clf_grid = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1)  \n",
    "    #clf_grid.fit(X_dataset, y_dataset)\n",
    "    #scores = clf_grid.best_score_ # mean cross-validated score of the best_estimator\n",
    "    #t_stop = process_time()\n",
    "    #part_l = [round(scores.mean(), 3), '-', str(datetime.timedelta(seconds=t_stop-t_start))]\n",
    "    #return part_l\n",
    "\n",
    "#Changing a bit of code because the line n_jobs=-1 tells RandomizedSearchCV to use all \n",
    "#available CPU cores for parallel processing.\n",
    "#n_jobs=1 limits processing to a single thread.\n",
    "#n_iter=min(10, total_combinations) ensures you don’t try more combinations than exist (which avoids another ValueError crash).\n",
    "def score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv):\n",
    "    \"\"\"\n",
    "    When there are hyper-parameters.\n",
    "    This function returns a list with the scores and processing times of model.\n",
    "    The scores are calculated with RandomizedSearchCV (with K-Fold equal to cv) (we use a random seed).\n",
    "    \"\"\"\n",
    "    t_start = process_time()\n",
    "\n",
    "    total_combinations = 1\n",
    "    for key in parameters:\n",
    "        total_combinations *= len(parameters[key])\n",
    "\n",
    "    n_iter = min(10, total_combinations)  # Safe cap to avoid crash\n",
    "\n",
    "    clf_grid = RandomizedSearchCV(model, parameters, cv=cv, n_iter=n_iter, random_state=1, n_jobs=1)\n",
    "    clf_grid.fit(X_dataset, y_dataset)\n",
    "    scores = clf_grid.best_score_\n",
    "    \n",
    "    t_stop = process_time()\n",
    "    part_l = [round(scores, 3), '-', str(datetime.timedelta(seconds=t_stop - t_start))]\n",
    "    return part_l\n",
    "\n",
    "\n",
    "\n",
    "def ml_benchmark(X_dataset, y_dataset, cv):\n",
    "    print('The shape of X_dataset is :', X_dataset.shape)\n",
    "    print('The shape of y_dataset is :', y_dataset.shape)\n",
    "\n",
    "    rows_name = [\"Logistic Regression\", \"Nearest Neighbors\", \"Naive Bayes\",\n",
    "                 \"Perceptron\", \"SVM\", \"Random Forest\", \"Multi-Layer Perceptron\"]\n",
    "\n",
    "    columns_name = ['Approx. mean of scores', 'Approx. variance of scores', 'Processing time']\n",
    "    l = []\n",
    "\n",
    "    # Logistic Regression\n",
    "    model = linear_model.LogisticRegression()\n",
    "    parameters = {\n",
    "        'solver': ['lbfgs', 'sag', 'saga'],\n",
    "        'multi_class': ['multinomial'],\n",
    "        'warm_start': [True, False],\n",
    "        'C': [0.01, 0.1, 1, 10]\n",
    "    }\n",
    "    l.append(score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv))\n",
    "\n",
    "    # Nearest Neighbors\n",
    "    model = neighbors.KNeighborsClassifier()\n",
    "    parameters = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'algorithm': ['auto', 'kd_tree']\n",
    "    }\n",
    "    l.append(score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv))\n",
    "\n",
    "    # Naive Bayes\n",
    "    model = naive_bayes.GaussianNB()\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "\n",
    "    # Perceptron\n",
    "    model = linear_model.Perceptron()\n",
    "    l.append(score_and_time(model, X_dataset, y_dataset, cv))\n",
    "\n",
    "    # SVM\n",
    "    model = SVC(kernel='rbf', class_weight='balanced')\n",
    "    parameters = {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "    l.append(score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv))\n",
    "\n",
    "    # Random Forest\n",
    "    model = RandomForestClassifier()\n",
    "    parameters = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, 50],\n",
    "        'bootstrap': [True],\n",
    "        'max_features': ['sqrt'],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'criterion': ['gini'],\n",
    "        'random_state': [0]\n",
    "    }\n",
    "    l.append(score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv))\n",
    "\n",
    "    # Multi-Layer Perceptron\n",
    "    model = neural_network.MLPClassifier()\n",
    "    parameters = {\n",
    "        'solver': ['adam'],                             # Faster than lbfgs, good for medium data\n",
    "        'max_iter': [500, 1000],                        # Enough for convergence\n",
    "        'alpha': [0.0001, 0.001],                       # Regularization\n",
    "        'hidden_layer_sizes': [(10,), (20,), (10, 5)],  # Mix of shallow and moderately deep\n",
    "        'activation': ['relu', 'tanh']                  # Cover both major activations\n",
    "    }\n",
    "    l.append(score_and_time_hyp(model, parameters, X_dataset, y_dataset, cv))\n",
    "\n",
    "    out = pd.DataFrame(l, index=rows_name, columns=columns_name)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our benchmarking function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is : (100, 99)\n",
      "The shape of y_dataset is : (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx. mean of scores</th>\n",
       "      <th>Approx. variance of scores</th>\n",
       "      <th>Processing time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <td>0.69</td>\n",
       "      <td>-</td>\n",
       "      <td>0:00:00.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.69</td>\n",
       "      <td>-</td>\n",
       "      <td>0:00:09.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.66</td>\n",
       "      <td>-</td>\n",
       "      <td>0:00:00.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-</td>\n",
       "      <td>0:00:00.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-</td>\n",
       "      <td>0:00:10.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0:00:00.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Approx. mean of scores Approx. variance of scores  \\\n",
       "Nearest Neighbors                         0.69                          -   \n",
       "Random Forest                             0.69                          -   \n",
       "Logistic Regression                       0.66                          -   \n",
       "SVM                                       0.65                          -   \n",
       "Multi-Layer Perceptron                    0.64                          -   \n",
       "Perceptron                                0.57                      0.258   \n",
       "Naive Bayes                               0.52                       0.28   \n",
       "\n",
       "                       Processing time  \n",
       "Nearest Neighbors       0:00:00.875000  \n",
       "Random Forest           0:00:09.234375  \n",
       "Logistic Regression     0:00:00.328125  \n",
       "SVM                     0:00:00.203125  \n",
       "Multi-Layer Perceptron  0:00:10.859375  \n",
       "Perceptron              0:00:00.015625  \n",
       "Naive Bayes                    0:00:00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_benchmark = ml_benchmark(X_dataset, y_dataset, 5)\n",
    "real_benchmark.to_csv('real_benchmark.csv', sep=';') # saving the results\n",
    "\n",
    "real_benchmark_sorted = real_benchmark.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "real_benchmark_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"output\"></a>\n",
    "# 3) Predicting the column `target` with (only) the fictitious generated dataset\n",
    "\n",
    "## 3.1) Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 99) (10000,)\n"
     ]
    }
   ],
   "source": [
    "df = df_fict\n",
    "X_dataset = df.loc[:, df.columns != target].values\n",
    "y_dataset = np.ravel(df.loc[:, df.columns == target].values)\n",
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is : (10000, 99)\n",
      "The shape of y_dataset is : (10000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d214548c4698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfict_benchmark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml_benchmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfict_benchmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fict_benchmark.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# saving the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfict_benchmark_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfict_benchmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Approx. mean of scores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfict_benchmark_sorted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-116732a1bc80>\u001b[0m in \u001b[0;36mml_benchmark\u001b[1;34m(X_dataset, y_dataset, cv)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     }\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_and_time_hyp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-116732a1bc80>\u001b[0m in \u001b[0;36mscore_and_time_hyp\u001b[1;34m(model, parameters, X_dataset, y_dataset, cv)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mclf_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mclf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mt_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1245\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m   1246\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "fict_benchmark = ml_benchmark(X_dataset, y_dataset, 5)\n",
    "fict_benchmark.to_csv('fict_benchmark.csv', sep=';') # saving the results\n",
    "\n",
    "fict_benchmark_sorted = fict_benchmark.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "fict_benchmark_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"aug\"></a>\n",
    "# 4) Predicting the column `target` with data augmentation\n",
    "\n",
    "## 4.1) Preparing the data\n",
    "\n",
    "We concatenate the real-life dataset `df_real` and the fictitious generated dataset `df_fict` into an augmented dataset `df_aug`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 99) (10100,)\n"
     ]
    }
   ],
   "source": [
    "df_aug = df_real.append(df_fict)\n",
    "\n",
    "X_dataset = df_aug.loc[:, df_aug.columns != target].values\n",
    "y_dataset = np.ravel(df_aug.loc[:, df_aug.columns == target].values)\n",
    "print(X_dataset.shape, y_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_dataset is : (10100, 99)\n",
      "The shape of y_dataset is : (10100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "aug_benchmark = ml_benchmark(X_dataset, y_dataset, 5)\n",
    "aug_benchmark.to_csv('aug_benchmark.csv', sep=';') # saving the results\n",
    "\n",
    "aug_benchmark_sorted = aug_benchmark.sort_values(by=['Approx. mean of scores'], ascending=False)\n",
    "aug_benchmark_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) Comparison: can data augmentation boost the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = real_benchmark['Approx. mean of scores'].values\n",
    "yaxis = aug_benchmark['Approx. mean of scores'].values\n",
    "\n",
    "start = min(np.min(xaxis), np.min(yaxis))\n",
    "stop = max(np.max(xaxis), np.max(yaxis))\n",
    "p = len(xaxis)\n",
    "X = np.linspace(start, stop, num=p+1)\n",
    "\n",
    "plt.plot(xaxis, yaxis, 'ok', X, X, '-g');\n",
    "\n",
    "plt.legend(['Approx. mean of scores', 'Equal approx. mean of scores'])\n",
    "plt.title('Boosting the prediction score with data augmentation')\n",
    "plt.xlabel('For the real dataset')\n",
    "plt.ylabel('For the augmented dataset')\n",
    "plt.savefig('comparison_small.png', dpi=120) # to save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe graphically the increase in the prediction score. The values of the $x$-axis and the $y$-axis are ordered.\n",
    "The diagonal green line indicates where the real and the augmented data show identical performance for a given machine learning model. Based on the graph, we can say that `medGAN` can perform data augmentation and boost the prediction score. Indeed, the dots are mostly on top of the green line.\n",
    "\n",
    "By what percentage did we increase of prediction score of our best machine learning models with data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_real = real_benchmark['Approx. mean of scores'].values\n",
    "score_aug = aug_benchmark['Approx. mean of scores'].values\n",
    "score_inc = (score_aug-score_real)/score_real*100\n",
    "df_score_inc = round(pd.DataFrame(score_inc, index=real_benchmark.index.values, columns=['Prediction score increase (%)']), 2)\n",
    "df_score_inc.to_csv('scores_increase_small.csv', sep=';')\n",
    "df_score_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_ml = real_benchmark_sorted.index.values[0]\n",
    "print('The best machine learning model on the original real-life dataset is :', best_ml)\n",
    "best_ml_aug = aug_benchmark_sorted.index.values[0]\n",
    "print('The best machine learning model on the augmented dataset is :', best_ml_aug)\n",
    "\n",
    "percentage = df_score_inc.loc[[best_ml], ['Prediction score increase (%)']].values[0][0]\n",
    "print('We increased the prediction score of', best_ml, 'by approx.', percentage, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data augmentation, we have an increase in score: up to almost 5%!\n",
    "\n",
    "However, **we should not try to measure the score increase of data augmentation with a cross-validation because `target` would contain fictitious generated values**.\n",
    "\n",
    "In the previous table and graph, we showed that data augmentation can boost the prediction score. However, we kind of cheated because half of the values of `target` in `aug` are fictitious generated values from `fict`. Thus, we try to use fictitious features to predict a `target` feature that is also fictitious. Hence, the score increase is natural and not due to data augmentation itself.\n",
    "\n",
    "We now try to avoid this problem by dividing our datasets into train/test and choosing our hyper-parameters with a randomzied search (using a random seed for reproducibility). We take take `real` (or `aug`) for the training set and we take only real-life values for the test set. The real-life values for the test set will come from values from the full MIMIC-III dataset. We recall that we only took 1 000 samples out of the 46 520 for `real`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"aug2\"></a>\n",
    "# 5) Can training on the augmented dataset help improve the prediction score with a real-life test set?\n",
    "\n",
    "\n",
    "## 5.1) Without data augmentation\n",
    "\n",
    "### 5.1.a) Loading the data\n",
    "\n",
    "#### Training set\n",
    "\n",
    "We now split our `real` dataset of shape (1 000, 100) into `X_train` and `y_train` (that is actually `target`). We try to use `X_train` and `y_train` to build a model that can predict $y$ for an unseen $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_real.loc[:, df_real.columns != target].values\n",
    "y_train = np.ravel(df_real.loc[:, df_real.columns == target].values)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set\n",
    "\n",
    "For the `test` set, we randomly select 250 samples (and the same 100 features as `real`) from the complete MIMIC-III dataset of shape (46 520, 1 071) that are not already samples in `real`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the full real-life test:\n",
    "real_data_array_full = pickle.load(open('training-data.matrix', 'rb'))\n",
    "df_real_full = pd.DataFrame(real_data_array_full)\n",
    "\n",
    "# We select that are not already in df_real:\n",
    "df_test = df_real_full[~df_real_full.isin(df_real)].dropna().sample(250, random_state=56)\n",
    "\n",
    "# We select the same rows as df_real:\n",
    "df_test = df_test.sample(100, axis=1, random_state=1)\n",
    "\n",
    "# We only select some rows for the real-life dataset to be the test set\n",
    "n,p = df_aug.shape\n",
    "print('The shape of the augmented training set is', (n,p))\n",
    "print('The shape of our test set is', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our `test` dataset of shape (250, 100) into `X_test` and `{y_test` (that is actually `target`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.loc[:, df_test.columns != target].values\n",
    "y_test = np.ravel(df_test.loc[:, df_test.columns == target].values)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.b) Benchmarking some models according to their score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let `model` be a machine learning model of our benchmark such as the perceptron. We fit the model with `model.fit(X_train, y_train)` then compute the score with `model.score(X_test, y_test)`.\n",
    "\n",
    "We define our benchmarking function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X_train, y_train, X_test, y_test):\n",
    "    t_start = process_time()\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    t_stop = process_time()\n",
    "    return [round(score, 3), str(datetime.timedelta(seconds=t_stop-t_start))]\n",
    "\n",
    "def ml_benchmark(X_train, y_train, X_test, y_test, cv):\n",
    "    \"\"\"\n",
    "    This function returns a pandas dataframe with the scores and processing times of some classic\n",
    "    machine learning models.\n",
    "    If there are hyper-parameters, there are computed with RandomizedSearchCV.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('The shape of X_train is :', X_train.shape)\n",
    "    print('The shape of y_train is :', y_train.shape)\n",
    "     \n",
    "    rows_name = [\"Logistic Regression\", \"Nearest Neighbors\", \"Naive Bayes\",\n",
    "                  \"Perceptron\", \"SVM\", \"Random Forest\", \"Multi-Layer Perceptron\"]\n",
    "    \n",
    "    columns_name = ['Approx. score', 'Processing time']\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    model = linear_model.LogisticRegression()\n",
    "    parameters = {'solver': ['lbfgs','liblinear','sag','saga'], 'multi_class': ['auto'],\n",
    "                 'warm_start': [True, False], 'C': [0.01,0.1,1,10,100]}\n",
    "    clf_grid = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1)  \n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    final_model = linear_model.LogisticRegression(**clf_grid.best_params_)\n",
    "    l.append(score(final_model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    model = neighbors.KNeighborsClassifier()\n",
    "    parameters = {'n_neighbors': [1,2,3,5,8,10,20], 'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "    clf_grid = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1)  \n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    final_model = neighbors.KNeighborsClassifier(**clf_grid.best_params_)\n",
    "    l.append(score(final_model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    model = naive_bayes.GaussianNB()\n",
    "    l.append(score(model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    model = linear_model.Perceptron()\n",
    "    l.append(score(model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    model = SVC(kernel='rbf', class_weight='balanced')\n",
    "    parameters = {'C': [0.0001, 0.001, 0.005, 0.01, 0.1, 0, 10, 1e2, 1e3, 1e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]}\n",
    "    clf_grid = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1)  \n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    final_model = SVC(kernel='rbf', class_weight='balanced', **clf_grid.best_params_)\n",
    "    l.append(score(final_model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    parameters = {'n_estimators': [1000], 'max_depth': [1,10,25,50], \"bootstrap\": [True, False],\n",
    "                  \"max_features\": [1, 3, 10], \"min_samples_split\": [2, 3, 10],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"], 'random_state': [0]}\n",
    "    clf_grid = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1)  \n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    final_model = RandomForestClassifier(**clf_grid.best_params_)\n",
    "    l.append(score(final_model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    model = neural_network.MLPClassifier()\n",
    "    parameters = {'solver': ['lbfgs'], 'max_iter': [1,500,1000,1500,2000], 'alpha': 10.0**-np.arange(1,5),\n",
    "                  'hidden_layer_sizes': np.arange(1,15,2),'activation': ['relu','tanh']}\n",
    "    clf_grid = RandomizedSearchCV(model, parameters, cv=cv, random_state=1, n_jobs=-1)  \n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    final_model = neural_network.MLPClassifier(**clf_grid.best_params_)\n",
    "    l.append(score(final_model, X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    out = pd.DataFrame(l, index = rows_name, columns = columns_name)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our benchmarking function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_benchmark_2 = ml_benchmark(X_train, y_train, X_test, y_test, 5)\n",
    "real_benchmark_2.to_csv('real_benchmark_2.csv', sep=';') # saving the results\n",
    "\n",
    "real_benchmark_2_sorted = real_benchmark_2.sort_values(by=['Approx. score'], ascending=False)\n",
    "real_benchmark_2_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_aug.loc[:, df_aug.columns != target].values\n",
    "y_train = np.ravel(df_aug.loc[:, df_aug.columns == target].values)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_benchmark_2 = ml_benchmark(X_train, y_train, X_test, y_test, 5)\n",
    "aug_benchmark_2.to_csv('aug_benchmark_2.csv', sep=';') # saving the results\n",
    "\n",
    "aug_benchmark_2_sorted = aug_benchmark_2.sort_values(by=['Approx. score'], ascending=False)\n",
    "aug_benchmark_2_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3) Comparison: can data augmentation boost the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = real_benchmark_2['Approx. score'].values\n",
    "yaxis = aug_benchmark_2['Approx. score'].values\n",
    "\n",
    "start = min(np.min(xaxis), np.min(yaxis))\n",
    "stop = max(np.max(xaxis), np.max(yaxis))\n",
    "p = len(xaxis)\n",
    "X = np.linspace(start, stop, num=p+1)\n",
    "\n",
    "plt.plot(xaxis, yaxis, 'ok', X, X, '-g');\n",
    "\n",
    "plt.legend(['Approx. mean of scores', 'Equal approx. mean of scores'])\n",
    "plt.title('Boosting the prediction score with data augmentation')\n",
    "plt.xlabel('For the real dataset')\n",
    "plt.ylabel('For the augmented dataset')\n",
    "plt.savefig('comparison_small_2.png', dpi=120) # to save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_real_2 = real_benchmark_2['Approx. score'].values\n",
    "score_aug_2 = aug_benchmark_2['Approx. score'].values\n",
    "score_inc_2 = (score_aug_2-score_real_2)/score_real_2*100\n",
    "df_score_inc_2 = round(pd.DataFrame(score_inc_2, index=real_benchmark.index.values, columns=['Prediction score increase (%)']), 2)\n",
    "df_score_inc_2.to_csv('scores_increase_small_2.csv', sep=';')\n",
    "df_score_inc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ml = real_benchmark_2_sorted.index.values[0]\n",
    "print('The best machine learning model on the original real-life dataset is :', best_ml)\n",
    "best_ml_aug = aug_benchmark_2_sorted.index.values[0]\n",
    "print('The best machine learning model on the augmented dataset is :', best_ml_aug)\n",
    "\n",
    "percentage = df_score_inc_2.loc[[best_ml], ['Prediction score increase (%)']].values[0][0]\n",
    "print('We increased the prediction score of', best_ml, 'by approx.', percentage, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Back to [top](#top)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
