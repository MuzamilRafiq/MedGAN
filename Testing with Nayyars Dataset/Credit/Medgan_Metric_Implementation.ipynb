{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4316d4",
   "metadata": {},
   "source": [
    "# Final 7-Metric Evaluation (with TSTR, JSD, WD)\n",
    "This notebook evaluates synthetic data using:\n",
    "- Logistic Regression (LR)\n",
    "- Random Forest (RF)\n",
    "- MLP\n",
    "- XGBoost (XGBT)\n",
    "- Jensen-Shannon Divergence (JSD)\n",
    "- Wasserstein Distance (WD)\n",
    "- TSTR (Train on Synthetic, Test on Real)\n",
    "\n",
    "**Setup:**\n",
    "- 3 runs of 2-fold cross-validation\n",
    "- Uses 50% of `synthetic_credit.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f7b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9f1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load synthetic\n",
    "synthetic_data = np.load('synthetic_credit.npy', allow_pickle=True)\n",
    "half_size = synthetic_data.shape[0] // 2\n",
    "synthetic_data = synthetic_data[:half_size]\n",
    "synthetic_labels = np.random.randint(0, 2, size=half_size)\n",
    "\n",
    "# Create dummy real data of same shape\n",
    "np.random.seed(42)\n",
    "real_data = np.random.rand(*synthetic_data.shape)\n",
    "real_labels = np.random.randint(0, 2, size=real_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0142a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_distributions(real, synth):\n",
    "    jsd = [jensenshannon(real[:, i], synth[:, i]) for i in range(real.shape[1])]\n",
    "    wd = [wasserstein_distance(real[:, i], synth[:, i]) for i in range(real.shape[1])]\n",
    "    return np.mean(jsd), np.mean(wd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee4fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_tstr(real_X, real_y, synth_X, synth_y):\n",
    "    model = MLPClassifier(max_iter=1000)\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in skf.split(real_X, real_y):\n",
    "        model.fit(synth_X, synth_y)\n",
    "        preds = model.predict(real_X[test_idx])\n",
    "        scores.append(accuracy_score(real_y[test_idx], preds))\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ed6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_all_metrics(X, y, seed=42):\n",
    "    models = {\n",
    "        \"LR\": LogisticRegression(max_iter=500),\n",
    "        \"MLP\": MLPClassifier(max_iter=500),\n",
    "        \"RF\": RandomForestClassifier(),\n",
    "        \"XGBT\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "    metrics_summary = {name: {\"ACC\": [], \"F1\": [], \"Precision\": [], \"Recall\": [], \"AUC\": []} for name in models}\n",
    "\n",
    "    for repeat in range(3):\n",
    "        for model_name, model in models.items():\n",
    "            for train_idx, test_idx in skf.split(X, y):\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "                preds = model.predict(X[test_idx])\n",
    "                probas = model.predict_proba(X[test_idx])[:, 1]\n",
    "\n",
    "                metrics_summary[model_name][\"ACC\"].append(accuracy_score(y[test_idx], preds))\n",
    "                metrics_summary[model_name][\"F1\"].append(f1_score(y[test_idx], preds))\n",
    "                metrics_summary[model_name][\"Precision\"].append(precision_score(y[test_idx], preds))\n",
    "                metrics_summary[model_name][\"Recall\"].append(recall_score(y[test_idx], preds))\n",
    "                metrics_summary[model_name][\"AUC\"].append(roc_auc_score(y[test_idx], probas))\n",
    "\n",
    "    results = []\n",
    "    for model_name in models:\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"ACC\": np.mean(metrics_summary[model_name][\"ACC\"]),\n",
    "            \"F1\": np.mean(metrics_summary[model_name][\"F1\"]),\n",
    "            \"Precision\": np.mean(metrics_summary[model_name][\"Precision\"]),\n",
    "            \"Recall\": np.mean(metrics_summary[model_name][\"Recall\"]),\n",
    "            \"AUC\": np.mean(metrics_summary[model_name][\"AUC\"])\n",
    "        })\n",
    "\n",
    "    jsd, wd = evaluate_distributions(real_data, X)\n",
    "    tstr = evaluate_tstr(real_data, real_labels, X, y)\n",
    "\n",
    "    results.append({\"Model\": \"JSD\", \"ACC\": None, \"F1\": None, \"Precision\": None, \"Recall\": None, \"AUC\": jsd})\n",
    "    results.append({\"Model\": \"WD\", \"ACC\": None, \"F1\": None, \"Precision\": None, \"Recall\": None, \"AUC\": wd})\n",
    "    results.append({\"Model\": \"TSTR\", \"ACC\": None, \"F1\": None, \"Precision\": None, \"Recall\": None, \"AUC\": tstr})\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7baaa9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.490353</td>\n",
       "      <td>0.491345</td>\n",
       "      <td>0.489434</td>\n",
       "      <td>0.480501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.497467</td>\n",
       "      <td>0.484620</td>\n",
       "      <td>0.498742</td>\n",
       "      <td>0.473889</td>\n",
       "      <td>0.499284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.482664</td>\n",
       "      <td>0.501725</td>\n",
       "      <td>0.465099</td>\n",
       "      <td>0.497209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBT</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.492026</td>\n",
       "      <td>0.496288</td>\n",
       "      <td>0.487841</td>\n",
       "      <td>0.490629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JSD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       ACC        F1  Precision    Recall       AUC\n",
       "0    LR  0.490000  0.490353   0.491345  0.489434  0.480501\n",
       "1   MLP  0.497467  0.484620   0.498742  0.473889  0.499284\n",
       "2    RF  0.500200  0.482664   0.501725  0.465099  0.497209\n",
       "3  XGBT  0.495000  0.492026   0.496288  0.487841  0.490629\n",
       "4   JSD       NaN       NaN        NaN       NaN  0.336118\n",
       "5    WD       NaN       NaN        NaN       NaN  0.446122\n",
       "6  TSTR       NaN       NaN        NaN       NaN  0.499600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluation_df = evaluate_all_metrics(synthetic_data, synthetic_labels)\n",
    "evaluation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9263186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
